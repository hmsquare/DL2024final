{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmsquare/DL2024final/blob/VQA-competition/240718_DLfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oeZaQMJqHSS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNTeita_qhBH"
      },
      "source": [
        "## installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A8SCJ8rBzHww",
        "outputId": "657af11b-3582-43c4-f83b-a4cdb564b6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/03_AY2425/04_5_DL/_final/'\n",
            "/content\n",
            "Cloning into 'unilm'...\n",
            "remote: Enumerating objects: 10134, done.\u001b[K\n",
            "remote: Counting objects: 100% (2092/2092), done.\u001b[K\n",
            "remote: Compressing objects: 100% (669/669), done.\u001b[K\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/microsoft/unilm.git\n",
        "%cd /content/drive/MyDrive/03_AY2425/04_5_DL/_final/\n",
        "!git clone https://github.com/hmsquare/unilm.git\n",
        "# %cd /content/drive/MyDrive/03_AY2425/04_5_DL/_final/unilm/beit3\n",
        "# # !git pull\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRrARYRxqipi"
      },
      "source": [
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3XxOtEE0tNp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "import os\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import sys\n",
        "import platform\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from transformers import XLMRobertaTokenizer\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TISnsbDH80v",
        "outputId": "6b13c3ff-d0bd-4649-97e8-cb56c27c5400"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def normalize_word_nltk(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = text.lower().strip().split()  # Split the string into words\n",
        "    normalized_words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatize each word\n",
        "\n",
        "    return ' '.join(normalized_words)  # Join the words back into a single string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vQ1jsZH2d_K"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    # 'EPOCHS': 30,\n",
        "    # 'LEARNING_RATE': 2e-5,\n",
        "    # 'BATCH_SIZE': 32,\n",
        "    'SEED': 42,\n",
        "    # 'MAX_LEN': 16,\n",
        "}\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GflGQBw9IGV4"
      },
      "source": [
        "# data transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE6eZyB_odqQ"
      },
      "source": [
        "## for custom"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "adhering to the DACON codes"
      ],
      "metadata": {
        "id": "URyMlwqWTyE3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ig9ZeoMN2iP2"
      },
      "outputs": [],
      "source": [
        "tf = open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/train.json')\n",
        "train_json = json.load(tf)\n",
        "\n",
        "items_train = []\n",
        "images_train = list(train_json['image'].items())\n",
        "questions_train = list(train_json['question'].items())\n",
        "answers_train = list(train_json['answers'].items())\n",
        "\n",
        "for i, img in images_train:\n",
        "  item = {}\n",
        "  item['id'] = int(i)\n",
        "  item['image'] = img\n",
        "  item['question'] = questions_train[int(i)][1]\n",
        "  item['answer'] = answers_train[int(i)][-1]\n",
        "\n",
        "  items_train.append(item)\n",
        "\n",
        "\n",
        "train_items, val_items = train_test_split(items_train, test_size=0.15, random_state=CFG['SEED'])\n",
        "\n",
        "with open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beit_json/train.json', \"w\") as json_file:\n",
        "  json.dump(train_items, json_file)\n",
        "\n",
        "with open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beit_json/val.json', \"w\") as json_file:\n",
        "  json.dump(val_items, json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_RZQX1aXNE7G"
      },
      "outputs": [],
      "source": [
        "vf = open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/valid.json')\n",
        "valid_json = json.load(vf)\n",
        "\n",
        "items_valid = []\n",
        "images_valid = list(valid_json['image'].items())\n",
        "questions_valid = list(valid_json['question'].items())\n",
        "\n",
        "\n",
        "for i, img in images_valid:\n",
        "  item = {}\n",
        "  item['id'] = int(i)\n",
        "  item['image'] = img\n",
        "  item['question'] = questions_valid[int(i)][1]\n",
        "\n",
        "  items_valid.append(item)\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beit_json/test.json', \"w\") as json_file:\n",
        "  json.dump(items_valid, json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8uiVp-7oftb"
      },
      "source": [
        "## for vqav2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "returning to adhere to the BEiT-3 codes"
      ],
      "metadata": {
        "id": "2ZovUPOLT13W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yXbt79srohMR"
      },
      "outputs": [],
      "source": [
        "btft = open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beit_json/train.json')\n",
        "btft_data = json.load(btft)\n",
        "newdict_t, trainimgs, trainqs, trainans = {}, [], [],[]\n",
        "for data in btft_data:\n",
        "  imgdict = {}\n",
        "  imgdict['image_id'] = data['image'].split('_')[-1][:5]\n",
        "  imgdict['image_path'] = data['image']\n",
        "  trainimgs.append(imgdict)\n",
        "\n",
        "  qdict = {}\n",
        "  qdict['image_id'] = data['image'].split('_')[-1][:5]\n",
        "  qdict['question'] = data['question']\n",
        "  qdict['question_id'] = int(data['image'].split('_')[-1][:5])*1000\n",
        "  trainqs.append(qdict)\n",
        "\n",
        "  adict = {}\n",
        "  adict['image_id'] = data['image'].split('_')[-1][:5]\n",
        "  adict['question_id'] = int(data['image'].split('_')[-1][:5])*1000\n",
        "  adict['multiple_choice_answer'] = Counter([ansdict['answer'] for ansdict in data['answer']]).most_common()[0][0]\n",
        "  adict['answer'] = data['answer']\n",
        "  trainans.append(adict)\n",
        "\n",
        "newdict_t['images'] = trainimgs\n",
        "newdict_t['questions'] = trainqs\n",
        "newdict_t['annotations'] = trainans\n",
        "\n",
        "with open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beitvqa_json/train.json', \"w\") as json_file:\n",
        "  json.dump(newdict_t, json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "klxSC9jD8yZO"
      },
      "outputs": [],
      "source": [
        "btfv = open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beit_json/val.json')\n",
        "btfv_data = json.load(btfv)\n",
        "newdict_v, valqs, valans, valimgs = {}, [], [], []\n",
        "for data in btfv_data:\n",
        "  imgdict = {}\n",
        "  imgdict['image_id'] = data['image'].split('_')[-1][:5]\n",
        "  imgdict['image_path'] = data['image']\n",
        "  valimgs.append(imgdict)\n",
        "\n",
        "  qdict = {}\n",
        "  qdict['image_id'] = data['image'].split('_')[-1][:5]\n",
        "  qdict['question'] = data['question']\n",
        "  qdict['question_id'] = int(data['image'].split('_')[-1][:5])*1000\n",
        "  valqs.append(qdict)\n",
        "\n",
        "  adict = {}\n",
        "  adict['image_id'] = data['image'].split('_')[-1][:5]\n",
        "  adict['question_id'] = int(data['image'].split('_')[-1][:5])*1000\n",
        "  adict['multiple_choice_answer'] = Counter([ansdict['answer'] for ansdict in data['answer']]).most_common()[0][0]\n",
        "  adict['answer'] = data['answer']\n",
        "  valans.append(adict)\n",
        "\n",
        "newdict_t['images'] = trainimgs\n",
        "newdict_v['questions'] = valqs\n",
        "newdict_v['annotations'] = valans\n",
        "\n",
        "with open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beitvqa_json/val.json', \"w\") as json_file:\n",
        "  json.dump(newdict_v, json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EONnlRBdGE_c"
      },
      "outputs": [],
      "source": [
        "# # = = = debug area = = =\n",
        "# ama = [d['multiple_choice_answer'] for d in trainans + valans]\n",
        "# all_major_answers = [normalize_word_nltk(word) for word in ama]\n",
        "# counter = {k: v for k, v in Counter(all_major_answers).items()} # if v >= 9} # for choosing the major ans\n",
        "# ans2label = {k: i for i, k in enumerate(counter.keys())}\n",
        "# label2ans = list(counter.keys())\n",
        "\n",
        "# normalize_word_nltk('csi cant stand idiots')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuuh5n2W_p6R"
      },
      "outputs": [],
      "source": [
        "btfs = open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beit_json/test.json')\n",
        "btfs_data = json.load(btfs)\n",
        "newdict_s, testims, testqs = {}, [], []\n",
        "for data in btfs_data:\n",
        "  imgdict = {}\n",
        "  imgdict['image_id'] = data['image'].split('_')[-1][:5]\n",
        "  imgdict['image_path'] = data['image']\n",
        "  testims.append(imgdict)\n",
        "\n",
        "  qdict = {}\n",
        "  qdict['image_id'] = data['image'].split('_')[-1][:5]\n",
        "  qdict['question'] = data['question']\n",
        "  qdict['question_id'] = int(data['image'].split('_')[-1][:5])*1000\n",
        "  testqs.append(qdict)\n",
        "\n",
        "newdict_s['questions'] = testqs\n",
        "newdict_s['images'] = testims\n",
        "\n",
        "with open('/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beitvqa_json/test.json', \"w\") as json_file:\n",
        "  json.dump(newdict_s, json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLMtQEi6TVV5"
      },
      "source": [
        "# pytorch dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppf9XosTbuhm"
      },
      "source": [
        "## required classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from BEiT-3 with debugging suggestions by ChatGPT"
      ],
      "metadata": {
        "id": "202XTXvqT_WG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrdascaNlFhb"
      },
      "source": [
        "### BaseDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q22IucMZvYn"
      },
      "outputs": [],
      "source": [
        "class BaseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self, data_path, split, transform,\n",
        "        tokenizer, num_max_bpe_tokens, task=None,\n",
        "    ):\n",
        "        index_files = self.get_index_files(split, task=task)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.num_max_bpe_tokens = num_max_bpe_tokens\n",
        "        self.data_path = data_path\n",
        "        items = []\n",
        "        self.index_files = index_files\n",
        "\n",
        "        offset = 0\n",
        "        for _index_file in index_files:\n",
        "            index_file = os.path.join(data_path, _index_file)\n",
        "            with open(index_file, mode=\"r\", encoding=\"utf-8\") as reader:\n",
        "                for line in reader:\n",
        "                    data = json.loads(line)\n",
        "                    items.append(data)\n",
        "                print(\"Load %d image-text pairs from %s. \" % (len(items) - offset, index_file))\n",
        "                offset = len(items)\n",
        "        self.items = items\n",
        "        self.bos_token_id = tokenizer.bos_token_id\n",
        "        self.eos_token_id = tokenizer.eos_token_id\n",
        "        self.pad_token_id = tokenizer.pad_token_id\n",
        "        self.loader = default_loader\n",
        "        self.transform = transform\n",
        "        self.split = split\n",
        "\n",
        "    @staticmethod\n",
        "    def get_index_files(split):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _get_image(self, image_path: str):\n",
        "        image_path = os.path.join(self.data_path, image_path)\n",
        "        image = self.loader(image_path)\n",
        "        return self.transform(image)\n",
        "\n",
        "    def _get_text_segment(self, text_segment, max_len=None):\n",
        "        if isinstance(text_segment, str):\n",
        "            tokens = self.tokenizer.tokenize(text_segment)\n",
        "        else:\n",
        "            tokens = text_segment[:]\n",
        "        if len(tokens) == 0:\n",
        "            raise RuntimeError(\"The text segment should contains at least one tokens!\")\n",
        "        if max_len is None:\n",
        "            max_len = self.num_max_bpe_tokens\n",
        "\n",
        "        if len(tokens) > max_len - 2:\n",
        "            tokens = tokens[:max_len - 2]\n",
        "\n",
        "        tokens = [self.bos_token_id] + tokens[:] + [self.eos_token_id]\n",
        "        num_tokens = len(tokens)\n",
        "        padding_mask = [0] * num_tokens + [1] * (max_len - num_tokens)\n",
        "        return tokens + [self.pad_token_id] * (max_len - num_tokens), padding_mask, num_tokens\n",
        "\n",
        "    def _get_image_text_example(self, index: int, data: dict):\n",
        "        item = self.items[index]\n",
        "        img_path = item[\"image_path\"]\n",
        "        img = self._get_image(img_path)\n",
        "        data[\"image\"] = img\n",
        "\n",
        "        text_segment = item[\"text_segment\"]\n",
        "        language_tokens, padding_mask, _ = self._get_text_segment(text_segment)\n",
        "        data[\"language_tokens\"] = language_tokens\n",
        "        data[\"padding_mask\"] = padding_mask\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        data = dict()\n",
        "        self._get_image_text_example(index, data)\n",
        "        return data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.items)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        head = \"Dataset \" + self.__class__.__name__\n",
        "        body = '{' + \"\\n  Number of items: %s,\" % self.__len__()\n",
        "        body += \"\\n  data root = %s,\" % self.data_path\n",
        "        body += \"\\n  split = %s,\" % self.split\n",
        "        body += \"\\n  dataset index files = %s\" % str(self.index_files)\n",
        "        body += \"\\n  num max bpe tokens = %s\" % self.num_max_bpe_tokens\n",
        "        body += \"\\n  transforms = [\"\n",
        "        for t in self.transform.transforms:\n",
        "            body += \"\\n    %s\" % str(t)\n",
        "        body += \"\\n  ]\"\n",
        "        body += \"\\n}\"\n",
        "\n",
        "        return head + body\n",
        "\n",
        "\n",
        "def _write_data_into_jsonl(items, jsonl_file):\n",
        "    with open(jsonl_file, mode=\"w\", encoding=\"utf-8\") as writer:\n",
        "        for data in items:\n",
        "            writer.write(json.dumps(data, indent=None))\n",
        "            writer.write('\\n')\n",
        "    print(\"Write %s with %d items !\" % (jsonl_file, len(items)))\n",
        "\n",
        "\n",
        "def _make_retrieval_coco_karpathy_dataset_index(\n",
        "        data_path,\n",
        "        tokenizer,\n",
        "        split=(\"train\", \"restval\"),\n",
        "        split_name=\"train\",\n",
        "):\n",
        "    coco_karpathy_split_json_file = os.path.join(data_path, \"dataset_coco.json\")\n",
        "    items = []\n",
        "    image_counter = set()\n",
        "    print(\"read %s\" % coco_karpathy_split_json_file)\n",
        "    with open(coco_karpathy_split_json_file, mode=\"r\", encoding=\"utf-8\") as reader:\n",
        "        data = json.loads(reader.read())\n",
        "        for item in data[\"images\"]:\n",
        "            if item[\"split\"] in split:\n",
        "                image_path = os.path.join(item[\"filepath\"], item[\"filename\"])\n",
        "                for sent in item[\"sentences\"]:\n",
        "                    tokens = tokenizer.tokenize(sent[\"raw\"])\n",
        "                    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "                    items.append({\n",
        "                            \"image_path\": image_path,\n",
        "                            \"text_segment\": token_ids,\n",
        "                            \"image_id\": len(image_counter),\n",
        "                    })\n",
        "                if image_path not in image_counter:\n",
        "                    image_counter.add(image_path)\n",
        "    print(\"Find %d images and %d image-text pairs for karpathy dataset %s split !\" % \\\n",
        "        (len(image_counter), len(items), split_name))\n",
        "    index_file = os.path.join(data_path, \"coco_retrieval.%s.jsonl\" % split_name)\n",
        "    _write_data_into_jsonl(items, index_file)\n",
        "    pass\n",
        "\n",
        "\n",
        "def _make_captioning_coco_karpathy_dataset_index(\n",
        "        data_path,\n",
        "        tokenizer,\n",
        "        split=(\"train\", \"restval\"),\n",
        "        split_name=\"train\",\n",
        "):\n",
        "    coco_karpathy_split_json_file = os.path.join(data_path, \"dataset_coco.json\")\n",
        "    items = []\n",
        "    image_counter = set()\n",
        "    print(\"read %s\" % coco_karpathy_split_json_file)\n",
        "    with open(coco_karpathy_split_json_file, mode=\"r\", encoding=\"utf-8\") as reader:\n",
        "        data = json.loads(reader.read())\n",
        "        for item in data[\"images\"]:\n",
        "            if item[\"split\"] in split:\n",
        "                image_path = os.path.join(item[\"filepath\"], item[\"filename\"])\n",
        "                if item[\"split\"] in [\"train\", \"restval\"]:\n",
        "                    for sent in item[\"sentences\"]:\n",
        "                        tokens = tokenizer.tokenize(sent[\"raw\"])\n",
        "                        token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "                        items.append({\n",
        "                                \"image_path\": image_path,\n",
        "                                \"text_segment\": token_ids,\n",
        "                                \"image_id\": item[\"cocoid\"],\n",
        "                        })\n",
        "                else:\n",
        "                    items.append({\n",
        "                                \"image_path\": image_path,\n",
        "                                \"text_segment\": None,\n",
        "                                \"image_id\": item[\"cocoid\"],\n",
        "                    })\n",
        "                if image_path not in image_counter:\n",
        "                    image_counter.add(image_path)\n",
        "    print(\"Find %d images and %d image-text pairs for karpathy dataset %s split !\" % \\\n",
        "        (len(image_counter), len(items), split_name))\n",
        "    index_file = os.path.join(data_path, \"coco_captioning.%s.jsonl\" % split_name)\n",
        "    _write_data_into_jsonl(items, index_file)\n",
        "    pass\n",
        "\n",
        "\n",
        "def _make_nocaps_dataset_index(\n",
        "        data_path,\n",
        "        split=\"val\",\n",
        "):\n",
        "    if split == \"val\":\n",
        "        json_file = \"nocaps_val_4500_captions.json\"\n",
        "    elif split == \"test\":\n",
        "        json_file = \"nocaps_test_image_info.json\"\n",
        "    nocaps_split_json_file = os.path.join(data_path, json_file)\n",
        "    items = []\n",
        "    image_counter = set()\n",
        "    print(\"read %s\" % nocaps_split_json_file)\n",
        "    with open(nocaps_split_json_file, mode=\"r\", encoding=\"utf-8\") as reader:\n",
        "        data = json.loads(reader.read())\n",
        "        for item in data[\"images\"]:\n",
        "            image_path = os.path.join(split, item[\"file_name\"])\n",
        "            items.append({\n",
        "                \"image_path\": image_path,\n",
        "                \"text_segment\": None,\n",
        "                \"image_id\": item[\"id\"],\n",
        "            })\n",
        "\n",
        "            if image_path not in image_counter:\n",
        "                image_counter.add(image_path)\n",
        "\n",
        "    print(\"Find %d images and %d image-text pairs for nocaps dataset %s split !\" % \\\n",
        "        (len(image_counter), len(items), split))\n",
        "    index_file = os.path.join(data_path, \"nocaps.%s.jsonl\" % split)\n",
        "    _write_data_into_jsonl(items, index_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adRlzgYzlKH5"
      },
      "source": [
        "### VQAv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5ltD9w8lNrL"
      },
      "outputs": [],
      "source": [
        "class VQAv2Dataset(BaseDataset):\n",
        "    def __init__(self, data_path, **kwargs):\n",
        "        super().__init__(data_path=data_path, **kwargs)\n",
        "        ans2label_file = os.path.join(data_path, \"answer2label.txt\")\n",
        "        ans2label = {}\n",
        "        label2ans = []\n",
        "        with open(ans2label_file, mode=\"r\", encoding=\"utf-8\") as reader:\n",
        "            for i, line in enumerate(reader):\n",
        "                data = json.loads(line)\n",
        "                ans = data[\"answer\"]\n",
        "                label = data[\"label\"]\n",
        "                label = int(label)\n",
        "                assert label == i\n",
        "                ans2label[ans] = i\n",
        "                label2ans.append(ans)\n",
        "\n",
        "        self.ans2label = ans2label\n",
        "        self.label2ans = label2ans\n",
        "\n",
        "    @staticmethod\n",
        "    def get_index_files(split, task=None):\n",
        "        if split == \"train\":\n",
        "            return (\"vqa.train.jsonl\", \"vqa.trainable_val.jsonl\")\n",
        "        elif split == \"val\":\n",
        "            return (\"vqa.rest_val.jsonl\", )\n",
        "        elif split == \"test\":\n",
        "            return (\"vqa.test.jsonl\", )\n",
        "        elif split == \"test-dev\":\n",
        "            return (\"vqa.test-dev.jsonl\", )\n",
        "        else:\n",
        "            raise RuntimeError(\"split %s is not found!\" % split)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        data = super().__getitem__(index)\n",
        "        if \"labels\" in self.items[index] and len(self.items[index][\"labels\"]) > 0:\n",
        "            labels = [0.] * len(self.label2ans)\n",
        "            for l, s in zip(self.items[index][\"labels\"], self.items[index][\"scores\"]):\n",
        "                labels[l] = s\n",
        "            data[\"labels\"] = torch.FloatTensor(labels)\n",
        "        else:\n",
        "            data[\"qid\"] = self.items[index][\"qid\"]\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def get_score(occurences):\n",
        "        if occurences == 0:\n",
        "            return 0.0\n",
        "        elif occurences == 1:\n",
        "            return 0.3\n",
        "        elif occurences == 2:\n",
        "            return 0.6\n",
        "        elif occurences == 3:\n",
        "            return 0.9\n",
        "        else:\n",
        "            return 1.0\n",
        "\n",
        "    @classmethod\n",
        "    def make_dataset_index(cls, data_path, tokenizer, annotation_data_path):\n",
        "      # = = = LOAD JSON DATA = = =\n",
        "        with open(os.path.join(annotation_data_path, \"train.json\"), \"r\") as fp:\n",
        "            train_data = json.load(fp)\n",
        "            questions_train = train_data['questions']\n",
        "            annotations_train = train_data['annotations']\n",
        "        with open(os.path.join(annotation_data_path, \"val.json\"), \"r\") as fp:\n",
        "            val_data = json.load(fp)\n",
        "            questions_val = val_data['questions']\n",
        "            annotations_val = val_data['annotations']\n",
        "        with open(os.path.join(annotation_data_path, \"test.json\"), \"r\") as fp:\n",
        "            test_data = json.load(fp)\n",
        "            questions_test = test_data['questions']\n",
        "\n",
        "        annotations = dict()\n",
        "\n",
        "        # = = = PROCESS QUESTIONS = = =\n",
        "        for split, questions in zip(\n",
        "            [\"train\", \"val\", \"test\"],\n",
        "            [questions_train, questions_val, questions_test],\n",
        "        ):\n",
        "            _annot = defaultdict(dict)\n",
        "            for q in questions:\n",
        "                question_text = q['question']\n",
        "                tokens = tokenizer.tokenize(question_text)\n",
        "                token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "                assert q[\"question_id\"] not in _annot[int(q[\"image_id\"])]\n",
        "                _annot[int(q[\"image_id\"])][q[\"question_id\"]] = {\n",
        "                    \"question\": question_text,\n",
        "                    \"token_ids\": token_ids,\n",
        "                }\n",
        "\n",
        "            annotations[split] = _annot\n",
        "\n",
        "        # ====== TROUBLESHOOT POINT ======\n",
        "        print(\"Loaded annotations after question processing:\")\n",
        "        for split, qlist in zip([\"train\", \"val\", \"test\"],[questions_train, questions_val, questions_test]):\n",
        "            print(f\"{split} annotations: {len(annotations[split])} out of {len(qlist)}\")\n",
        "\n",
        "\n",
        "        # = = = PROCESS ANSWERS = = =\n",
        "\n",
        "        all_major_answers = list()\n",
        "\n",
        "        for split, annots in zip(\n",
        "            [\"train\", \"val\"], [annotations_train, annotations_val],\n",
        "        ):\n",
        "            # _annot = annotations[split]\n",
        "            for q in annots:\n",
        "                all_major_answers.append(q[\"multiple_choice_answer\"])\n",
        "\n",
        "        print('len all_major_answers:', len(all_major_answers))\n",
        "\n",
        "        all_major_answers = [normalize_word_nltk(word) for word in all_major_answers]\n",
        "        counter = {k: v for k, v in Counter(all_major_answers).items()} # if v >= 9} # for choosing the major ans\n",
        "        ans2label = {k: i for i, k in enumerate(counter.keys())}\n",
        "        label2ans = list(counter.keys())\n",
        "\n",
        "        for split, annots in zip(\n",
        "            [\"train\", \"val\"], [annotations_train, annotations_val],\n",
        "        ):\n",
        "            _annot = annotations[split]\n",
        "\n",
        "            for q in annots:\n",
        "                answer_count = {}\n",
        "                for ad in q['answer']:\n",
        "                    answer_ = ad[\"answer\"]\n",
        "                    answer_count[answer_] = answer_count.get(answer_, 0) + 1\n",
        "\n",
        "                labels = []\n",
        "                scores = []\n",
        "                for answer in answer_count:\n",
        "                    answer_n = normalize_word_nltk(answer)\n",
        "                    if answer_n not in ans2label:\n",
        "                        continue\n",
        "\n",
        "                    labels.append(ans2label[answer_n])\n",
        "                    score = cls.get_score(answer_count[answer])\n",
        "                    scores.append(score)\n",
        "\n",
        "                assert \"labels\" not in _annot[int(q[\"image_id\"])][q[\"question_id\"]]\n",
        "                assert \"question\" in _annot[int(q[\"image_id\"])][q[\"question_id\"]]\n",
        "                _annot[int(q[\"image_id\"])][q[\"question_id\"]][\"labels\"] = labels\n",
        "                _annot[int(q[\"image_id\"])][q[\"question_id\"]][\"scores\"] = scores\n",
        "\n",
        "                if (len(_annot[int(q[\"image_id\"])][q[\"question_id\"]][\"labels\"])) == 0:\n",
        "                  print(q['image_id'],q['multiple_choice_answer'])\n",
        "\n",
        "\n",
        "        # ====== TROUBESHOOT POINT ======\n",
        "        for split,alist in zip([\"train\", \"val\"],[annotations_train, annotations_val]):\n",
        "          print(f\"Total annotations in {split} after adding answers: {len(annotations[split])} out of {len(alist)}\")\n",
        "\n",
        "        # - - - filtering - - - (comment out block if not needed)\n",
        "        # for split in [\"train\", \"val\"]:\n",
        "        #     filtered_annot = dict()\n",
        "        #     for ik, iv in annotations[split].items():\n",
        "        #         new_q = dict()\n",
        "        #         for qk, qv in iv.items():\n",
        "        #             if len(qv[\"labels\"]) != 0:\n",
        "        #                 new_q[qk] = qv\n",
        "        #         if len(new_q) != 0:\n",
        "        #             filtered_annot[ik] = new_q\n",
        "        #     annotations[split] = filtered_annot\n",
        "\n",
        "        # for split in [\"train\", \"val\"]:\n",
        "        #   filtered_annot = dict()\n",
        "        #   for ik, iv in annotations[split].items():\n",
        "        #       new_q = dict()\n",
        "        #       for qk, qv in iv.items():\n",
        "        #           if len(qv[\"labels\"]) == 0:\n",
        "        #               print(f\"Removing question ID {qk} from image ID {ik} because it has no labels.\")\n",
        "        #               print(annotations[split][ik])\n",
        "        #           else:\n",
        "        #               new_q[qk] = qv\n",
        "        #       if len(new_q) == 0:\n",
        "        #           print(f\"Removing image ID {ik} because it has no questions with labels.\")\n",
        "        #       else:\n",
        "        #           filtered_annot[ik] = new_q\n",
        "        #   annotations[split] = filtered_annot\n",
        "\n",
        "        # # ====== TROUBESHOOT POINT ======\n",
        "        # for split,alist in zip([\"train\", \"val\"],[annotations_train, annotations_val]):\n",
        "        #   print(f\"Total annotations in {split} after filtering: {len(annotations[split])} out of {len(alist)}\")\n",
        "\n",
        "        split2items = {}\n",
        "        print('\\n\\nSplitting to items... \\n')\n",
        "\n",
        "        for split in [\"train\", \"val\", \"test\"]:\n",
        "            print(f\"Processing {split}...\")\n",
        "            annot = annotations[split]\n",
        "            split_name = {\n",
        "                \"train\": \"train\",\n",
        "                \"val\": \"train\",\n",
        "                \"test\": \"valid\"\n",
        "            }[split]\n",
        "            paths = list(glob.glob(f\"{data_path}/{split_name}/*.jpg\"))\n",
        "            random.shuffle(paths)\n",
        "\n",
        "            # # ====== TROUBLESHOOT POINT ======\n",
        "            print(f\"Total images in {split}: {len(paths)}\")\n",
        "\n",
        "            annot_paths = [path for path in paths \\\n",
        "                if int(path.split(\"/\")[-1].split(\"_\")[-1][:-4]) in annot]\n",
        "\n",
        "            # ====== TROUBLESHOOTING ======\n",
        "            # annot_paths = []\n",
        "            # for path in paths:\n",
        "            #     img_id = int(path.split(\"/\")[-1].split(\"_\")[-1][:-4])\n",
        "            #     if img_id in annot:\n",
        "            #         annot_paths.append(path)\n",
        "            #     else:\n",
        "            #         print(f\"Image {path} with ID {img_id} is not in annotations\")\n",
        "\n",
        "\n",
        "        #     # **GEMINI SUGGEST**\n",
        "        #     # Create a set of image IDs from the annotation data for efficient lookup\n",
        "        #     annot_image_ids = [int(i) for i in list(set(annot.keys()))]\n",
        "        #     annot_paths = [path for path in paths if int(path.split(\"/\")[-1].split(\"_\")[-1][:-5]) in annot_image_ids]\n",
        "\n",
        "\n",
        "            if len(paths) == len(annot_paths):\n",
        "                print(\"all images have caption annotations\")\n",
        "            else:\n",
        "                print(\"not all images have caption annotations\")\n",
        "            print(len(paths), len(annot_paths), len(annot))\n",
        "\n",
        "            items = []\n",
        "            for path in annot_paths:\n",
        "                iid = int(path.split(\"/\")[-1].split(\"_\")[-1][:-4])\n",
        "                _annot = annotations[split][iid]\n",
        "                for qid in _annot:\n",
        "                    q = _annot[qid]\n",
        "                    if split in [\"train\", \"val\"]:\n",
        "                        labels = q[\"labels\"]\n",
        "                        scores = q[\"scores\"]\n",
        "                    else:\n",
        "                        labels, scores = [], []\n",
        "\n",
        "                    items.append({\n",
        "                        \"image_path\": os.path.join(split_name, path.split('/')[-1]),\n",
        "                        \"text_segment\": q[\"token_ids\"],\n",
        "                        \"labels\": labels,\n",
        "                        \"scores\": scores,\n",
        "                        \"qid\": qid,\n",
        "                    })\n",
        "\n",
        "                # **GEMINI: Check if the image ID exists in annotations before accessing it\n",
        "                # if iid in annotations[split]:\n",
        "                #     _annot = annotations[split][iid]\n",
        "                #     for qid in _annot:\n",
        "                #         q = _annot[qid]\n",
        "                #         if split in [\"train\", \"val\"]:\n",
        "                #             labels = q[\"labels\"]\n",
        "                #             scores = q[\"scores\"]\n",
        "                #         else:\n",
        "                #             labels, scores = [], []\n",
        "\n",
        "                #         items.append({\n",
        "                #             \"image_path\": os.path.join(split_name, path.split('/')[-1]),\n",
        "                #             \"text_segment\": q[\"token_ids\"],\n",
        "                #             \"labels\": labels,\n",
        "                #             \"scores\": scores,\n",
        "                #             \"qid\": qid,\n",
        "                #         })\n",
        "                # else:\n",
        "                #     print(f\"Warning: Image ID {iid} not found in annotations for split {split}\") # Print a warning if an image ID is missing\n",
        "\n",
        "\n",
        "            split2items[split] = items\n",
        "            print(f'len for split2items_{split}: {len(split2items[split])}')\n",
        "\n",
        "            _write_data_into_jsonl(items=items, jsonl_file=os.path.join(data_path, \"vqa.%s.jsonl\" % split))\n",
        "\n",
        "            print(f\"Finished processing {split}! \\n\")\n",
        "\n",
        "        # Following ViLT, we use 1000 images of the original val set as the final val set\n",
        "        val_image2items = defaultdict(list)\n",
        "        for item in split2items[\"val\"]:\n",
        "            val_image2items[item[\"image_path\"]].append(item)\n",
        "\n",
        "        print(\"Contains %d image and %d pairs for val set!\" % (len(val_image2items), len(split2items[\"val\"])))\n",
        "\n",
        "        val_images = list(val_image2items.keys())\n",
        "        random.shuffle(val_images)\n",
        "        trainable_val = []\n",
        "        rest_val = []\n",
        "        for i, image_id in enumerate(val_images):\n",
        "            if i < 1000:\n",
        "                rest_val += val_image2items[image_id]\n",
        "            else:\n",
        "                trainable_val += val_image2items[image_id]\n",
        "\n",
        "        _write_data_into_jsonl(items=trainable_val, jsonl_file=os.path.join(data_path, \"vqa.trainable_val.jsonl\"))\n",
        "        _write_data_into_jsonl(items=rest_val, jsonl_file=os.path.join(data_path, \"vqa.rest_val.jsonl\"))\n",
        "\n",
        "        with open(os.path.join(data_path, \"answer2label.txt\"), mode=\"w\", encoding=\"utf-8\") as writer:\n",
        "            for ans in ans2label:\n",
        "                to_json = {\n",
        "                    \"answer\": ans,\n",
        "                    \"label\": ans2label[ans]\n",
        "                }\n",
        "                writer.write(\"%s\\n\" % json.dumps(to_json))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exZGm5M0bxgA"
      },
      "source": [
        "## make dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwiGRAigH5n3",
        "outputId": "c23adcb4-811e-448c-b85e-1e94d2c5b830",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded annotations after question processing:\n",
            "train annotations: 16892 out of 16892\n",
            "val annotations: 2981 out of 2981\n",
            "test annotations: 4969 out of 4969\n",
            "len all_major_answers: 19873\n",
            "Total annotations in train after adding answers: 16892 out of 16892\n",
            "Total annotations in val after adding answers: 2981 out of 2981\n",
            "\n",
            "\n",
            "Splitting to items... \n",
            "\n",
            "Processing train...\n",
            "Total images in train: 19873\n",
            "not all images have caption annotations\n",
            "19873 16892 16892\n",
            "len for split2items_train: 16892\n",
            "Write /content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/vqa.train.jsonl with 16892 items !\n",
            "Finished processing train! \n",
            "\n",
            "Processing val...\n",
            "Total images in val: 19873\n",
            "not all images have caption annotations\n",
            "19873 2981 2981\n",
            "len for split2items_val: 2981\n",
            "Write /content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/vqa.val.jsonl with 2981 items !\n",
            "Finished processing val! \n",
            "\n",
            "Processing test...\n",
            "Total images in test: 4969\n",
            "all images have caption annotations\n",
            "4969 4969 4969\n",
            "len for split2items_test: 4969\n",
            "Write /content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/vqa.test.jsonl with 4969 items !\n",
            "Finished processing test! \n",
            "\n",
            "Contains 2981 image and 2981 pairs for val set!\n",
            "Write /content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/vqa.trainable_val.jsonl with 1981 items !\n",
            "Write /content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/vqa.rest_val.jsonl with 1000 items !\n"
          ]
        }
      ],
      "source": [
        "# This code creates an index according to the format learned by the BEIT-3 model.\n",
        "# from datasets import CustomDataset\n",
        "# from transformers import XLMRobertaTokenizer\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer(\"/content/drive/MyDrive/03_AY2425/04_5_DL/_final/beit_models/beit3.spm\")\n",
        "\n",
        "dataset = VQAv2Dataset.make_dataset_index(\n",
        "    data_path=\"/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/\",\n",
        "    tokenizer=tokenizer,\n",
        "    annotation_data_path=\"/content/drive/MyDrive/03_AY2425/04_5_DL/_final/data/beitvqa_json/\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_rH1PEDh0We"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joO73fn-uvmj",
        "outputId": "7024348c-e890-48f9-cb7f-c40374b22a95",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul 17 23:38:55 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0              50W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for when running the code from another Google account"
      ],
      "metadata": {
        "id": "bPmfCl7aUKO5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g1DijIXtF3um"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/_final\n",
        "# !git clone https://github.com/hmsquare/unilm.git\n",
        "%cd /content/drive/MyDrive/_final/unilm/beit3\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pjzs8Avfuhd"
      },
      "source": [
        "### epoch0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2rXiweYVGC4U",
        "outputId": "98863043-8d03-4aca-f3d8-f1d5b903dc36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not using distributed mode\n",
            "Namespace(model='beit3_base_patch16_384', task='vqav2', input_size=384, drop_path=0.15, checkpoint_activations=True, sentencepiece_model='/content/drive/MyDrive/_final/beit_models/beit3.spm', vocab_size=64010, num_max_bpe_tokens=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=[0.9, 0.98], clip_grad=None, momentum=0.9, weight_decay=0.01, lr=2e-05, layer_decay=1.0, task_head_lr_weight=20.0, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=0, warmup_steps=-1, batch_size=256, eval_batch_size=None, epochs=1, update_freq=1, save_ckpt_freq=5, randaug=True, train_interpolation='bicubic', finetune='/content/drive/MyDrive/_final/beit_models/beit3_base_indomain_patch16_224.pth', model_key='model|module', model_prefix='', data_path='/content/drive/MyDrive/_final/data/', output_dir='/content/drive/MyDrive/_final/finetuned_models/', log_dir='/content/drive/MyDrive/_final/finetuned_models/log', device='cuda', seed=42, resume='', auto_resume=False, save_ckpt=True, start_epoch=0, eval=False, dist_eval=False, num_workers=10, pin_mem=True, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', task_cache_path='/content/drive/MyDrive/_final/finetuned_models/', nb_classes=1000, mixup=0, cutmix=0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, captioning_mask_prob=0.6, drop_worst_ratio=0.2, drop_worst_after=12000, num_beams=3, length_penalty=0.6, label_smoothing=0.1, enable_deepspeed=False, initial_scale_power=16, zero_stage=0, distributed=False)\n",
            "Load 16892 image-text pairs from /content/drive/MyDrive/_final/data/vqa.train.jsonl. \n",
            "Load 1981 image-text pairs from /content/drive/MyDrive/_final/data/vqa.trainable_val.jsonl. \n",
            "Load 1000 image-text pairs from /content/drive/MyDrive/_final/data/vqa.rest_val.jsonl. \n",
            "model_config = beit3_base_patch16_384_vqav2\n",
            "Load ckpt from /content/drive/MyDrive/_final/beit_models/beit3_base_indomain_patch16_224.pth\n",
            "Load state_dict by model_key = model\n",
            "Position interpolate from 14x14 to 24x24\n",
            "Weights of BEiT3ForVisualQuestionAnswering not initialized from pretrained model: ['pooler.norm.weight', 'pooler.norm.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'head.0.weight', 'head.0.bias', 'head.1.weight', 'head.1.bias', 'head.3.weight', 'head.3.bias']\n",
            "Weights from pretrained model not used in BEiT3ForVisualQuestionAnswering: ['mlm_head.weight', 'mlm_head.bias', 'mim_head.weight', 'mim_head.bias', 'beit3.encoder.layer_norm.A.weight', 'beit3.encoder.layer_norm.A.bias', 'beit3.encoder.layer_norm.B.weight', 'beit3.encoder.layer_norm.B.bias']\n",
            "Model = BEiT3ForVisualQuestionAnswering(\n",
            "  (beit3): BEiT3(\n",
            "    (text_embed): TextEmbedding(64010, 768)\n",
            "    (vision_embed): VisionEmbedding(\n",
            "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "    )\n",
            "    (encoder): Encoder(\n",
            "      (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "      (embed_positions): MutliwayEmbedding(\n",
            "        (A): PositionalEmbedding(579, 768)\n",
            "        (B): PositionalEmbedding(1024, 768)\n",
            "      )\n",
            "      (layers): ModuleList(\n",
            "        (0): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.0)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (1): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.013636363636363636)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (2): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.02727272727272727)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (3): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.04090909090909091)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (4): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.05454545454545454)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (5): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.06818181818181818)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (6): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.08181818181818182)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (7): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.09545454545454544)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (8): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.10909090909090909)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (9): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.12272727272727273)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (10): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.13636363636363635)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (11): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.15)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): Pooler(\n",
            "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
            "    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): Linear(in_features=1536, out_features=5206, bias=True)\n",
            "  )\n",
            ")\n",
            "number of params: 231054166\n",
            "LR = 0.00002000\n",
            "Batch size = 256\n",
            "Update frequent = 1\n",
            "Number of training examples = 18873\n",
            "Number of training training per epoch = 73\n",
            "Assigned values = [1.0, 20.0]\n",
            "Param groups = {\n",
            "  \"layer_0_decay\": {\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"params\": [\n",
            "      \"beit3.text_embed.weight\",\n",
            "      \"beit3.vision_embed.mask_token\",\n",
            "      \"beit3.vision_embed.proj.weight\",\n",
            "      \"beit3.encoder.embed_positions.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc2.weight\",\n",
            "      \"pooler.dense.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"layer_0_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.vision_embed.cls_token\",\n",
            "      \"beit3.vision_embed.proj.bias\",\n",
            "      \"beit3.encoder.embed_positions.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.B.bias\",\n",
            "      \"pooler.norm.weight\",\n",
            "      \"pooler.norm.bias\",\n",
            "      \"pooler.dense.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"layer_1_decay\": {\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"params\": [\n",
            "      \"head.0.weight\",\n",
            "      \"head.3.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 20.0\n",
            "  },\n",
            "  \"layer_1_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"head.0.bias\",\n",
            "      \"head.1.weight\",\n",
            "      \"head.1.bias\",\n",
            "      \"head.3.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 20.0\n",
            "  }\n",
            "}\n",
            "Set warmup steps = 0\n",
            "Start training for 1 epochs\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "Warning: NaN or Inf found in input tensor.\n",
            "Epoch: [0]  [ 0/73]  eta: 4:46:45  lr: 0.000400  min_lr: 0.000020  loss: 3662.8184 (3662.8184)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: inf (inf)  time: 235.6855  data: 230.1613  max mem: 27153\n",
            "Warning: NaN or Inf found in input tensor.\n",
            "Warning: NaN or Inf found in input tensor.\n",
            "Warning: NaN or Inf found in input tensor.\n",
            "Warning: NaN or Inf found in input tensor.\n",
            "Warning: NaN or Inf found in input tensor.\n",
            "Warning: NaN or Inf found in input tensor.\n",
            "Epoch: [0]  [10/73]  eta: 0:43:40  lr: 0.000383  min_lr: 0.000019  loss: 3662.8184 (3310.8876)  loss_scale: 1024.0000 (6144.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: inf (inf)  time: 41.5915  data: 37.6119  max mem: 28921\n",
            "Epoch: [0]  [20/73]  eta: 0:28:41  lr: 0.000334  min_lr: 0.000017  loss: 1590.0614 (2058.4818)  loss_scale: 512.0000 (3462.0952)  weight_decay: 0.0100 (0.0100)  grad_norm: 703.2430 (inf)  time: 22.3142  data: 18.4949  max mem: 28921\n",
            "Epoch: [0]  [30/73]  eta: 0:20:54  lr: 0.000262  min_lr: 0.000013  loss: 174.2204 (1427.3374)  loss_scale: 512.0000 (2510.4516)  weight_decay: 0.0100 (0.0100)  grad_norm: 81.8255 (inf)  time: 22.3335  data: 18.5204  max mem: 28921\n",
            "Epoch: [0]  [40/73]  eta: 0:15:01  lr: 0.000181  min_lr: 0.000009  loss: 55.8251 (1090.0979)  loss_scale: 512.0000 (2023.0244)  weight_decay: 0.0100 (0.0100)  grad_norm: 25.6633 (inf)  time: 21.9258  data: 18.1135  max mem: 28921\n",
            "Epoch: [0]  [50/73]  eta: 0:10:05  lr: 0.000106  min_lr: 0.000005  loss: 36.3414 (882.9108)  loss_scale: 512.0000 (1726.7451)  weight_decay: 0.0100 (0.0100)  grad_norm: 15.5944 (inf)  time: 21.9281  data: 18.1168  max mem: 28921\n",
            "Epoch: [0]  [60/73]  eta: 0:05:32  lr: 0.000049  min_lr: 0.000002  loss: 31.1454 (743.1324)  loss_scale: 512.0000 (1527.6066)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.9837 (inf)  time: 21.8986  data: 18.0865  max mem: 28921\n",
            "Epoch: [0]  [70/73]  eta: 0:01:15  lr: 0.000022  min_lr: 0.000001  loss: 29.4779 (642.5740)  loss_scale: 512.0000 (1384.5634)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.0398 (inf)  time: 22.0123  data: 18.1998  max mem: 28921\n",
            "Epoch: [0]  [72/73]  eta: 0:00:24  lr: 0.000020  min_lr: 0.000001  loss: 29.4672 (625.7595)  loss_scale: 512.0000 (1360.6575)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.8969 (inf)  time: 22.0123  data: 18.1998  max mem: 28921\n",
            "Epoch: [0] Total time: 0:29:50 (24.5310 s / it)\n",
            "Averaged stats: lr: 0.000020  min_lr: 0.000001  loss: 29.4672 (625.7595)  loss_scale: 512.0000 (1360.6575)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.8969 (inf)\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "Test:  [0/3]  eta: 0:11:23  score: 52.1094 (52.1094)  time: 227.7352  data: 226.5924  max mem: 28921\n",
            "Test:  [2/3]  eta: 0:01:16  score: 52.1094 (51.0417)  time: 76.6235  data: 75.5309  max mem: 28921\n",
            "Test: Total time: 0:03:49 (76.6484 s / it)\n",
            "* Score 51.042\n",
            "Performance of the network on the 1000 val images: 51.0%\n",
            "Max performance: 51.04%\n",
            "Training time 0:34:52\n"
          ]
        }
      ],
      "source": [
        "!python run_beit3_finetuning.py \\\n",
        "        --model beit3_base_patch16_384 \\\n",
        "        --input_size 384 \\\n",
        "        --task vqav2 \\\n",
        "        --batch_size 256 \\\n",
        "        --layer_decay 1.0 \\\n",
        "        --lr 2e-5 \\\n",
        "        --update_freq 1 \\\n",
        "        --randaug \\\n",
        "        --epochs 1 \\\n",
        "        --warmup_epochs 0 \\\n",
        "        --drop_path 0.15 \\\n",
        "        --sentencepiece_model /content/drive/MyDrive/_final/beit_models/beit3.spm \\\n",
        "        --finetune /content/drive/MyDrive/_final/beit_models/beit3_base_indomain_patch16_224.pth \\\n",
        "        --data_path /content/drive/MyDrive/_final/data/ \\\n",
        "        --output_dir /content/drive/MyDrive/_final/finetuned_models/ \\\n",
        "        --log_dir /content/drive/MyDrive/_final/finetuned_models/log \\\n",
        "        --weight_decay 0.01 \\\n",
        "        --seed 42 \\\n",
        "        --no_auto_resume \\\n",
        "        --save_ckpt_freq 5 \\\n",
        "        --task_head_lr_weight 20 \\\n",
        "        --opt_betas 0.9 0.98 \\\n",
        "        --checkpoint_activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pjZ8NOsomqV"
      },
      "source": [
        "### from epoch 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdE96bhaxhDt",
        "outputId": "0c919185-1699-4e9c-9567-fea38829d670",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not using distributed mode\n",
            "Namespace(model='beit3_base_patch16_384', task='vqav2', input_size=384, drop_path=0.15, checkpoint_activations=True, sentencepiece_model='/content/drive/MyDrive/_final/beit_models/beit3.spm', vocab_size=64010, num_max_bpe_tokens=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=[0.9, 0.98], clip_grad=None, momentum=0.9, weight_decay=0.01, lr=2e-05, layer_decay=1.0, task_head_lr_weight=20.0, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=0, warmup_steps=-1, batch_size=256, eval_batch_size=None, epochs=10, update_freq=1, save_ckpt_freq=2, randaug=True, train_interpolation='bicubic', finetune='/content/drive/MyDrive/_final/finetuned_models/checkpoint-best.pth', model_key='model|module', model_prefix='', data_path='/content/drive/MyDrive/_final/data/', output_dir='/content/drive/MyDrive/_final/finetuned_models/', log_dir='/content/drive/MyDrive/_final/finetuned_models/log', device='cuda', seed=42, resume='', auto_resume=True, save_ckpt=True, start_epoch=0, eval=False, dist_eval=False, num_workers=10, pin_mem=True, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', task_cache_path='/content/drive/MyDrive/_final/finetuned_models/', nb_classes=1000, mixup=0, cutmix=0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, captioning_mask_prob=0.6, drop_worst_ratio=0.2, drop_worst_after=12000, num_beams=3, length_penalty=0.6, label_smoothing=0.1, enable_deepspeed=False, initial_scale_power=16, zero_stage=0, distributed=False)\n",
            "Load 16892 image-text pairs from /content/drive/MyDrive/_final/data/vqa.train.jsonl. \n",
            "Load 1981 image-text pairs from /content/drive/MyDrive/_final/data/vqa.trainable_val.jsonl. \n",
            "Load 1000 image-text pairs from /content/drive/MyDrive/_final/data/vqa.rest_val.jsonl. \n",
            "model_config = beit3_base_patch16_384_vqav2\n",
            "Load ckpt from /content/drive/MyDrive/_final/finetuned_models/checkpoint-best.pth\n",
            "Load state_dict by model_key = model\n",
            "Model = BEiT3ForVisualQuestionAnswering(\n",
            "  (beit3): BEiT3(\n",
            "    (text_embed): TextEmbedding(64010, 768)\n",
            "    (vision_embed): VisionEmbedding(\n",
            "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "    )\n",
            "    (encoder): Encoder(\n",
            "      (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "      (embed_positions): MutliwayEmbedding(\n",
            "        (A): PositionalEmbedding(579, 768)\n",
            "        (B): PositionalEmbedding(1024, 768)\n",
            "      )\n",
            "      (layers): ModuleList(\n",
            "        (0): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.0)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (1): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.013636363636363636)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (2): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.02727272727272727)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (3): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.04090909090909091)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (4): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.05454545454545454)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (5): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.06818181818181818)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (6): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.08181818181818182)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (7): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.09545454545454544)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (8): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.10909090909090909)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (9): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.12272727272727273)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (10): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.13636363636363635)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (11): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.15)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): Pooler(\n",
            "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
            "    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): Linear(in_features=1536, out_features=5206, bias=True)\n",
            "  )\n",
            ")\n",
            "number of params: 231054166\n",
            "LR = 0.00002000\n",
            "Batch size = 256\n",
            "Update frequent = 1\n",
            "Number of training examples = 18873\n",
            "Number of training training per epoch = 73\n",
            "Assigned values = [1.0, 20.0]\n",
            "Param groups = {\n",
            "  \"layer_0_decay\": {\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"params\": [\n",
            "      \"beit3.text_embed.weight\",\n",
            "      \"beit3.vision_embed.mask_token\",\n",
            "      \"beit3.vision_embed.proj.weight\",\n",
            "      \"beit3.encoder.embed_positions.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc2.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc2.weight\",\n",
            "      \"pooler.dense.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"layer_0_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.vision_embed.cls_token\",\n",
            "      \"beit3.vision_embed.proj.bias\",\n",
            "      \"beit3.encoder.embed_positions.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.B.bias\",\n",
            "      \"pooler.norm.weight\",\n",
            "      \"pooler.norm.bias\",\n",
            "      \"pooler.dense.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"layer_1_decay\": {\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"params\": [\n",
            "      \"head.0.weight\",\n",
            "      \"head.3.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 20.0\n",
            "  },\n",
            "  \"layer_1_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"head.0.bias\",\n",
            "      \"head.1.weight\",\n",
            "      \"head.1.bias\",\n",
            "      \"head.3.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 20.0\n",
            "  }\n",
            "}\n",
            "Set warmup steps = 0\n",
            "Auto resume checkpoint: /content/drive/MyDrive/_final/finetuned_models/checkpoint-7.pth\n",
            "Resume checkpoint /content/drive/MyDrive/_final/finetuned_models/checkpoint-7.pth\n",
            "With optim & sched!\n",
            "Start training for 10 epochs\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "Epoch: [8]  [ 0/73]  eta: 0:35:49  lr: 0.000056  min_lr: 0.000003  loss: 1.8691 (1.8691)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.1730 (5.1730)  time: 29.4433  data: 23.4916  max mem: 28918\n",
            "Epoch: [8]  [10/73]  eta: 0:06:28  lr: 0.000052  min_lr: 0.000003  loss: 2.0976 (2.0775)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.6312 (5.8493)  time: 6.1631  data: 2.1359  max mem: 28919\n",
            "Epoch: [8]  [20/73]  eta: 0:04:27  lr: 0.000047  min_lr: 0.000002  loss: 2.1100 (2.0987)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.5989 (5.7258)  time: 3.8252  data: 0.0003  max mem: 28919\n",
            "Epoch: [8]  [30/73]  eta: 0:03:19  lr: 0.000043  min_lr: 0.000002  loss: 2.1469 (2.1158)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.4250 (5.7411)  time: 3.8156  data: 0.0003  max mem: 28919\n",
            "Epoch: [8]  [40/73]  eta: 0:02:26  lr: 0.000039  min_lr: 0.000002  loss: 2.1469 (2.1212)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.4779 (5.7155)  time: 3.8159  data: 0.0003  max mem: 28919\n",
            "Epoch: [8]  [50/73]  eta: 0:01:39  lr: 0.000036  min_lr: 0.000002  loss: 2.1430 (2.1300)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.5206 (5.6634)  time: 3.8156  data: 0.0003  max mem: 28919\n",
            "Epoch: [8]  [60/73]  eta: 0:00:55  lr: 0.000033  min_lr: 0.000002  loss: 2.1756 (2.1396)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.3884 (5.5902)  time: 3.8153  data: 0.0002  max mem: 28919\n",
            "Epoch: [8]  [70/73]  eta: 0:00:12  lr: 0.000030  min_lr: 0.000002  loss: 2.1793 (2.1446)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.2447 (5.5639)  time: 3.8167  data: 0.0002  max mem: 28919\n",
            "Epoch: [8]  [72/73]  eta: 0:00:04  lr: 0.000030  min_lr: 0.000001  loss: 2.1742 (2.1427)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.2253 (5.5548)  time: 3.8167  data: 0.0002  max mem: 28919\n",
            "Epoch: [8] Total time: 0:05:04 (4.1761 s / it)\n",
            "Averaged stats: lr: 0.000030  min_lr: 0.000001  loss: 2.1742 (2.1427)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.2253 (5.5548)\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "Test:  [0/3]  eta: 0:00:43  score: 59.1797 (59.1797)  time: 14.6001  data: 13.4883  max mem: 28919\n",
            "Test:  [2/3]  eta: 0:00:05  score: 59.6484 (61.3802)  time: 5.5786  data: 4.4962  max mem: 28919\n",
            "Test: Total time: 0:00:16 (5.6502 s / it)\n",
            "* Score 61.380\n",
            "Performance of the network on the 1000 val images: 61.4%\n",
            "Max performance: 61.38%\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "Epoch: [9]  [ 0/73]  eta: 0:32:02  lr: 0.000029  min_lr: 0.000001  loss: 1.9840 (1.9840)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 4.8492 (4.8492)  time: 26.3422  data: 22.4352  max mem: 28919\n",
            "Epoch: [9]  [10/73]  eta: 0:06:11  lr: 0.000027  min_lr: 0.000001  loss: 2.0701 (2.0603)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.3400 (5.2174)  time: 5.8892  data: 2.0401  max mem: 28919\n",
            "Epoch: [9]  [20/73]  eta: 0:04:20  lr: 0.000025  min_lr: 0.000001  loss: 2.0360 (2.0321)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.0760 (5.0878)  time: 3.8408  data: 0.0005  max mem: 28919\n",
            "Epoch: [9]  [30/73]  eta: 0:03:16  lr: 0.000023  min_lr: 0.000001  loss: 2.0328 (2.0472)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.0498 (5.1484)  time: 3.8361  data: 0.0005  max mem: 28919\n",
            "Epoch: [9]  [40/73]  eta: 0:02:24  lr: 0.000022  min_lr: 0.000001  loss: 2.0518 (2.0443)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.0360 (5.1297)  time: 3.8251  data: 0.0004  max mem: 28919\n",
            "Epoch: [9]  [50/73]  eta: 0:01:38  lr: 0.000021  min_lr: 0.000001  loss: 2.0302 (2.0448)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 4.9431 (5.0880)  time: 3.8156  data: 0.0003  max mem: 28919\n",
            "Epoch: [9]  [60/73]  eta: 0:00:54  lr: 0.000020  min_lr: 0.000001  loss: 2.0943 (2.0637)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.0303 (5.1075)  time: 3.8154  data: 0.0002  max mem: 28919\n",
            "Epoch: [9]  [70/73]  eta: 0:00:12  lr: 0.000020  min_lr: 0.000001  loss: 2.1622 (2.0754)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.1260 (5.1318)  time: 3.8151  data: 0.0002  max mem: 28919\n",
            "Epoch: [9]  [72/73]  eta: 0:00:04  lr: 0.000020  min_lr: 0.000001  loss: 2.1473 (2.0744)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.1276 (5.1348)  time: 3.8151  data: 0.0001  max mem: 28919\n",
            "Epoch: [9] Total time: 0:05:02 (4.1393 s / it)\n",
            "Averaged stats: lr: 0.000020  min_lr: 0.000001  loss: 2.1473 (2.0744)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 5.1276 (5.1348)\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "Test:  [0/3]  eta: 0:00:44  score: 57.5000 (57.5000)  time: 14.8597  data: 13.7443  max mem: 28919\n",
            "Test:  [2/3]  eta: 0:00:05  score: 63.1641 (61.8359)  time: 5.6654  data: 4.5815  max mem: 28919\n",
            "Test: Total time: 0:00:17 (5.7346 s / it)\n",
            "* Score 61.836\n",
            "Performance of the network on the 1000 val images: 61.8%\n",
            "Max performance: 61.84%\n",
            "Training time 0:11:06\n"
          ]
        }
      ],
      "source": [
        "!python run_beit3_finetuning.py \\\n",
        "        --model beit3_base_patch16_384 \\\n",
        "        --input_size 384 \\\n",
        "        --task vqav2 \\\n",
        "        --batch_size 128 \\\n",
        "        --layer_decay 1.0 \\\n",
        "        --lr 2e-5 \\\n",
        "        --update_freq 1 \\\n",
        "        --randaug \\\n",
        "        --epochs 10 \\\n",
        "        --warmup_epochs 0 \\\n",
        "        --drop_path 0.15 \\\n",
        "        --sentencepiece_model /content/drive/MyDrive/_final/beit_models/beit3.spm \\\n",
        "        --finetune /content/drive/MyDrive/_final/finetuned_models/checkpoint-best.pth \\\n",
        "        --data_path /content/drive/MyDrive/_final/data/ \\\n",
        "        --output_dir /content/drive/MyDrive/_final/finetuned_models/ \\\n",
        "        --log_dir /content/drive/MyDrive/_final/finetuned_models/log \\\n",
        "        --weight_decay 0.01 \\\n",
        "        --seed 42 \\\n",
        "        --no_auto_resume \\\n",
        "        --save_ckpt_freq 2 \\\n",
        "        --task_head_lr_weight 20 \\\n",
        "        --opt_betas 0.9 0.98 \\\n",
        "        --checkpoint_activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6TrlWNXijMx"
      },
      "source": [
        "# inferencing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDDykKbKikU2",
        "outputId": "e720235d-9d5e-420f-c6b6-c13c3609a3de",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Namespace(model='beit3_base_patch16_384', task='vqav2', input_size=384, drop_path=0.1, checkpoint_activations=None, sentencepiece_model='/content/drive/MyDrive/_final/beit_models/beit3.spm', vocab_size=64010, num_max_bpe_tokens=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=[0.9, 0.999], clip_grad=None, momentum=0.9, weight_decay=0.05, lr=0.0005, layer_decay=0.9, task_head_lr_weight=0, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=5, warmup_steps=-1, batch_size=256, eval_batch_size=None, epochs=20, update_freq=1, save_ckpt_freq=5, randaug=False, train_interpolation='bicubic', finetune='/content/drive/MyDrive/_final/finetuned_models/checkpoint-best.pth', model_key='model|module', model_prefix='', data_path='/content/drive/MyDrive/_final/data', output_dir='/content/drive/MyDrive/_final/finetuned_models', log_dir=None, device='cuda', seed=0, resume='', auto_resume=False, save_ckpt=True, start_epoch=0, eval=True, dist_eval=False, num_workers=10, pin_mem=True, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', task_cache_path='/content/drive/MyDrive/_final/finetuned_models', nb_classes=1000, mixup=0, cutmix=0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, captioning_mask_prob=0.6, drop_worst_ratio=0.2, drop_worst_after=12000, num_beams=3, length_penalty=0.6, label_smoothing=0.1, enable_deepspeed=False, initial_scale_power=16, zero_stage=0, distributed=False)\n",
            "Load 16892 image-text pairs from /content/drive/MyDrive/_final/data/vqa.train.jsonl. \n",
            "Load 1981 image-text pairs from /content/drive/MyDrive/_final/data/vqa.trainable_val.jsonl. \n",
            "Load 1000 image-text pairs from /content/drive/MyDrive/_final/data/vqa.rest_val.jsonl. \n",
            "model_config = beit3_base_patch16_384_vqav2\n",
            "Load ckpt from /content/drive/MyDrive/_final/finetuned_models/checkpoint-best.pth\n",
            "Load state_dict by model_key = model\n",
            "Model = BEiT3ForVisualQuestionAnswering(\n",
            "  (beit3): BEiT3(\n",
            "    (text_embed): TextEmbedding(64010, 768)\n",
            "    (vision_embed): VisionEmbedding(\n",
            "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "    )\n",
            "    (encoder): Encoder(\n",
            "      (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "      (embed_positions): MutliwayEmbedding(\n",
            "        (A): PositionalEmbedding(579, 768)\n",
            "        (B): PositionalEmbedding(1024, 768)\n",
            "      )\n",
            "      (layers): ModuleList(\n",
            "        (0): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.0)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (1): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.009090909090909092)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (2): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.018181818181818184)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (3): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.027272727272727275)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (4): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.03636363636363637)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (5): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.04545454545454546)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (6): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.05454545454545455)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (7): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.06363636363636364)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (8): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.07272727272727274)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (9): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.08181818181818183)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (10): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.09090909090909093)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (11): EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (v_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (q_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (out_proj): MultiwayNetwork(\n",
            "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (inner_attn_ln): MultiwayNetwork(\n",
            "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (self_attn_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "          (drop_path): DropPath(p=0.1)\n",
            "          (ffn): MultiwayNetwork(\n",
            "            (A): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (B): FeedForwardNetwork(\n",
            "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (final_layer_norm): MultiwayNetwork(\n",
            "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): Pooler(\n",
            "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
            "    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): Linear(in_features=1536, out_features=5206, bias=True)\n",
            "  )\n",
            ")\n",
            "number of params: 231054166\n",
            "LR = 0.00050000\n",
            "Batch size = 256\n",
            "Update frequent = 1\n",
            "Number of training examples = 18873\n",
            "Number of training training per epoch = 73\n",
            "Assigned values = [0.2541865828329001, 0.2824295364810001, 0.31381059609000006, 0.3486784401000001, 0.3874204890000001, 0.4304672100000001, 0.4782969000000001, 0.531441, 0.5904900000000001, 0.6561, 0.7290000000000001, 0.81, 0.9, 1.0]\n",
            "Param groups = {\n",
            "  \"layer_0_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.text_embed.weight\",\n",
            "      \"beit3.vision_embed.mask_token\",\n",
            "      \"beit3.vision_embed.proj.weight\",\n",
            "      \"beit3.encoder.embed_positions.B.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.2541865828329001\n",
            "  },\n",
            "  \"layer_0_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.vision_embed.cls_token\",\n",
            "      \"beit3.vision_embed.proj.bias\",\n",
            "      \"beit3.encoder.embed_positions.A.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.2541865828329001\n",
            "  },\n",
            "  \"layer_1_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.2824295364810001\n",
            "  },\n",
            "  \"layer_1_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.0.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.0.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.0.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.2824295364810001\n",
            "  },\n",
            "  \"layer_2_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.31381059609000006\n",
            "  },\n",
            "  \"layer_2_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.1.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.1.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.1.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.31381059609000006\n",
            "  },\n",
            "  \"layer_3_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.3486784401000001\n",
            "  },\n",
            "  \"layer_3_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.2.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.2.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.2.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.3486784401000001\n",
            "  },\n",
            "  \"layer_4_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.3874204890000001\n",
            "  },\n",
            "  \"layer_4_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.3.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.3.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.3.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.3874204890000001\n",
            "  },\n",
            "  \"layer_5_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.4304672100000001\n",
            "  },\n",
            "  \"layer_5_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.4.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.4.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.4.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.4304672100000001\n",
            "  },\n",
            "  \"layer_6_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.4782969000000001\n",
            "  },\n",
            "  \"layer_6_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.5.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.5.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.5.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.4782969000000001\n",
            "  },\n",
            "  \"layer_7_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.531441\n",
            "  },\n",
            "  \"layer_7_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.6.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.6.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.6.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.531441\n",
            "  },\n",
            "  \"layer_8_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.5904900000000001\n",
            "  },\n",
            "  \"layer_8_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.7.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.7.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.7.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.5904900000000001\n",
            "  },\n",
            "  \"layer_9_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.6561\n",
            "  },\n",
            "  \"layer_9_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.8.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.8.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.8.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.6561\n",
            "  },\n",
            "  \"layer_10_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.7290000000000001\n",
            "  },\n",
            "  \"layer_10_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.9.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.9.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.9.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.7290000000000001\n",
            "  },\n",
            "  \"layer_11_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.81\n",
            "  },\n",
            "  \"layer_11_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.10.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.10.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.10.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.81\n",
            "  },\n",
            "  \"layer_12_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.B.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc1.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc2.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc1.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc2.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.9\n",
            "  },\n",
            "  \"layer_12_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.k_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.v_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.q_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.out_proj.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.B.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.11.self_attn_layer_norm.B.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc1.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.fc2.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.A.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc1.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.fc2.bias\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.ffn_layernorm.weight\",\n",
            "      \"beit3.encoder.layers.11.ffn.B.ffn_layernorm.bias\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.A.weight\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.A.bias\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.B.weight\",\n",
            "      \"beit3.encoder.layers.11.final_layer_norm.B.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 0.9\n",
            "  },\n",
            "  \"layer_13_no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"pooler.norm.weight\",\n",
            "      \"pooler.norm.bias\",\n",
            "      \"pooler.dense.bias\",\n",
            "      \"head.0.bias\",\n",
            "      \"head.1.weight\",\n",
            "      \"head.1.bias\",\n",
            "      \"head.3.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"layer_13_decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"pooler.dense.weight\",\n",
            "      \"head.0.weight\",\n",
            "      \"head.3.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Set warmup steps = 365\n",
            "Load 4969 image-text pairs from /content/drive/MyDrive/_final/data/vqa.test.jsonl. \n",
            "Test:  [ 0/13]  eta: 0:07:27    time: 34.4599  data: 30.9928  max mem: 21016\n",
            "Test:  [10/13]  eta: 0:00:13    time: 4.5818  data: 2.8177  max mem: 21016\n",
            "Test:  [12/13]  eta: 0:00:04    time: 4.1695  data: 2.3842  max mem: 21016\n",
            "Test: Total time: 0:00:54 (4.1910 s / it)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/run_beit3_finetuning.py\", line 448, in <module>\n",
            "    main(opts, ds_init)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/run_beit3_finetuning.py\", line 365, in main\n",
            "    utils.dump_predictions(args, result, \"vqav2_test\")\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1LvXP-6a3tiyiZUKk__pV3AsQXseiHNw9/_final/unilm/beit3/utils.py\", line 844, in dump_predictions\n",
            "    torch.distributed.barrier()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py\", line 75, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 3672, in barrier\n",
            "    opts.device = _get_pg_default_device(group)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 649, in _get_pg_default_device\n",
            "    group = group or _get_default_group()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 1008, in _get_default_group\n",
            "    raise ValueError(\n",
            "ValueError: Default process group has not been initialized, please make sure to call init_process_group.\n"
          ]
        }
      ],
      "source": [
        "!python run_beit3_finetuning.py \\\n",
        "        --model beit3_base_patch16_384 \\\n",
        "        --input_size 384 \\\n",
        "        --task vqav2 \\\n",
        "        --batch_size 256 \\\n",
        "        --sentencepiece_model /content/drive/MyDrive/_final/beit_models/beit3.spm \\\n",
        "        --finetune /content/drive/MyDrive/_final/finetuned_models/checkpoint-best.pth \\\n",
        "        --data_path /content/drive/MyDrive/_final/data\\\n",
        "        --output_dir /content/drive/MyDrive/_final/finetuned_models \\\n",
        "        --no_auto_resume \\\n",
        "        --eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ2Qrbm9irEo"
      },
      "source": [
        "# submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOZ4VGPPiqHp"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/_final/finetuned_models/submit_0_vqav2_test.json', \"r\") as json_file:\n",
        "    results = json.load(json_file)\n",
        "\n",
        "outputs = [r['answer'] for r in results]\n",
        "numpyArray = np.array(outputs)\n",
        "np.save('/content/drive/MyDrive/_final/results/240718_results_13.npy', numpyArray)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "lNTeita_qhBH",
        "rRrARYRxqipi",
        "GflGQBw9IGV4",
        "eE6eZyB_odqQ",
        "mLMtQEi6TVV5",
        "SOu_CSktF-du",
        "2Pjzs8Avfuhd",
        "6pjZ8NOsomqV",
        "GuNf4ui0F-9I"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}